{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 Split the dataset into training, validation and testing split of length 39664, 4959, 4959, respectively.\
Training model: TextClassifier(\
  (embedding): Embedding(10002, 16)\
  (fc1): Linear(in_features=16, out_features=16, bias=True)\
  (act1): ReLU()\
  (output_fc2): Linear(in_features=16, out_features=1, bias=True)\
  (sig): Sigmoid()\
), with learning rate: 0.001, batch size: 4, hidden dim: 16, embedding dim: 16 for 30 epochs.\
| Epoch 1:   5%|\uc0\u9608 \u9612                              | 499/9916 [00:00<00:05, 1728.21it/s] Step 500 of 9916. Loss: 0.6949. Time: 0:00:00.\
| Epoch 1:   9%|\uc0\u9608 \u9608 \u9611                             | 856/9916 [00:00<00:05, 1762.47it/s] Step 1000 of 9916. Loss: 0.6936. Time: 0:00:00.\
| Epoch 1:  14%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                          | 1429/9916 [00:00<00:04, 1867.14it/s] Step 1500 of 9916. Loss: 0.6931. Time: 0:00:00.\
| Epoch 1:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608                         | 1987/9916 [00:01<00:04, 1837.39it/s] Step 2000 of 9916. Loss: 0.6927. Time: 0:00:01.\
| Epoch 1:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                       | 2363/9916 [00:01<00:04, 1838.43it/s] Step 2500 of 9916. Loss: 0.6922. Time: 0:00:01.\
| Epoch 1:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                      | 2934/9916 [00:01<00:03, 1867.12it/s] Step 3000 of 9916. Loss: 0.6920. Time: 0:00:01.\
| Epoch 1:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                    | 3493/9916 [00:01<00:03, 1840.61it/s] Step 3500 of 9916. Loss: 0.6918. Time: 0:00:01.\
| Epoch 1:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                   | 3865/9916 [00:02<00:03, 1848.99it/s] Step 4000 of 9916. Loss: 0.6912. Time: 0:00:02.\
| Epoch 1:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                 | 4435/9916 [00:02<00:02, 1868.83it/s] Step 4500 of 9916. Loss: 0.6906. Time: 0:00:02.\
| Epoch 1:  48%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                | 4808/9916 [00:02<00:02, 1825.14it/s] Step 5000 of 9916. Loss: 0.6899. Time: 0:00:02.\
| Epoch 1:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614              | 5378/9916 [00:02<00:02, 1832.55it/s] Step 5500 of 9916. Loss: 0.6892. Time: 0:00:03.\
| Epoch 1:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609             | 5922/9916 [00:03<00:02, 1767.05it/s] Step 6000 of 9916. Loss: 0.6885. Time: 0:00:03.\
| Epoch 1:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6459/9916 [00:03<00:01, 1736.98it/s] Step 6500 of 9916. Loss: 0.6874. Time: 0:00:03.\
| Epoch 1:  71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615         | 6991/9916 [00:03<00:01, 1741.01it/s] Step 7000 of 9916. Loss: 0.6863. Time: 0:00:03.\
| Epoch 1:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614        | 7358/9916 [00:04<00:01, 1786.80it/s] Step 7500 of 9916. Loss: 0.6847. Time: 0:00:04.\
| Epoch 1:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609       | 7904/9916 [00:04<00:01, 1801.53it/s] Step 8000 of 9916. Loss: 0.6830. Time: 0:00:04.\
| Epoch 1:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8464/9916 [00:04<00:00, 1806.83it/s] Step 8500 of 9916. Loss: 0.6808. Time: 0:00:04.\
| Epoch 1:  89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611    | 8838/9916 [00:04<00:00, 1829.72it/s] Step 9000 of 9916. Loss: 0.6783. Time: 0:00:05.\
| Epoch 1:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613  | 9379/9916 [00:05<00:00, 1691.69it/s] Step 9500 of 9916. Loss: 0.6754. Time: 0:00:05.\
| Epoch 1: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1796.11it/s]\
Train accuracy for this epoch: 0.6142\
| Epoch validation 1: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 11912.69it/s]\
Val accuracy: 0.7966\
End of epoch 1/30, Train Loss: 0.6726, Val Loss: 0.6018, Train F1 Score: 0.6047784686088562, Val F1 Score: 0.8132, Learning rate scheduler: 0.0003555555555555555.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 2:   4%|\uc0\u9608 \u9615                              | 362/9916 [00:00<00:05, 1807.90it/s] Step 500 of 9916. Loss: 0.5960. Time: 0:00:00.\
| Epoch 2:   9%|\uc0\u9608 \u9608 \u9609                             | 920/9916 [00:00<00:04, 1823.15it/s] Step 1000 of 9916. Loss: 0.5875. Time: 0:00:00.\
| Epoch 2:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9613                          | 1469/9916 [00:00<00:04, 1774.68it/s] Step 1500 of 9916. Loss: 0.5766. Time: 0:00:00.\
| Epoch 2:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9612                         | 1828/9916 [00:01<00:04, 1776.07it/s] Step 2000 of 9916. Loss: 0.5670. Time: 0:00:01.\
| Epoch 2:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                       | 2376/9916 [00:01<00:04, 1794.68it/s] Step 2500 of 9916. Loss: 0.5571. Time: 0:00:01.\
| Epoch 2:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                      | 2919/9916 [00:01<00:03, 1759.98it/s] Step 3000 of 9916. Loss: 0.5471. Time: 0:00:01.\
| Epoch 2:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                    | 3447/9916 [00:01<00:03, 1736.30it/s] Step 3500 of 9916. Loss: 0.5374. Time: 0:00:01.\
| Epoch 2:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                   | 3982/9916 [00:02<00:03, 1760.89it/s] Step 4000 of 9916. Loss: 0.5285. Time: 0:00:02.\
| Epoch 2:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                  | 4338/9916 [00:02<00:03, 1763.09it/s] Step 4500 of 9916. Loss: 0.5216. Time: 0:00:02.\
| Epoch 2:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                | 4888/9916 [00:02<00:02, 1784.34it/s] Step 5000 of 9916. Loss: 0.5132. Time: 0:00:02.\
| Epoch 2:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613              | 5434/9916 [00:03<00:02, 1761.45it/s] Step 5500 of 9916. Loss: 0.5049. Time: 0:00:03.\
| Epoch 2:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5980/9916 [00:03<00:02, 1802.87it/s] Step 6000 of 9916. Loss: 0.4985. Time: 0:00:03.\
| Epoch 2:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615           | 6347/9916 [00:03<00:01, 1814.09it/s] Step 6500 of 9916. Loss: 0.4918. Time: 0:00:03.\
| Epoch 2:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6900/9916 [00:03<00:01, 1820.78it/s] Step 7000 of 9916. Loss: 0.4857. Time: 0:00:03.\
| Epoch 2:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7450/9916 [00:04<00:01, 1803.22it/s] Step 7500 of 9916. Loss: 0.4793. Time: 0:00:04.\
| Epoch 2:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611       | 7826/9916 [00:04<00:01, 1803.99it/s] Step 8000 of 9916. Loss: 0.4742. Time: 0:00:04.\
| Epoch 2:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8371/9916 [00:04<00:00, 1747.00it/s] Step 8500 of 9916. Loss: 0.4684. Time: 0:00:04.\
| Epoch 2:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609    | 8891/9916 [00:05<00:00, 1659.98it/s] Step 9000 of 9916. Loss: 0.4642. Time: 0:00:05.\
| Epoch 2:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9422/9916 [00:05<00:00, 1727.60it/s] Step 9500 of 9916. Loss: 0.4598. Time: 0:00:05.\
| Epoch 2: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1767.12it/s]\
Train accuracy for this epoch: 0.8255\
| Epoch validation 2: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12190.11it/s]\
Val accuracy: 0.8372\
End of epoch 2/30, Train Loss: 0.4566, Val Loss: 0.3864, Train F1 Score: 0.8297255039215088, Val F1 Score: 0.8336, Learning rate scheduler: 0.0003777777777777777.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 3:   4%|\uc0\u9608 \u9615                              | 360/9916 [00:00<00:05, 1678.57it/s] Step 500 of 9916. Loss: 0.3517. Time: 0:00:00.\
| Epoch 3:   9%|\uc0\u9608 \u9608 \u9610                             | 890/9916 [00:00<00:05, 1697.40it/s] Step 1000 of 9916. Loss: 0.3552. Time: 0:00:00.\
| Epoch 3:  14%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                          | 1414/9916 [00:00<00:04, 1726.83it/s] Step 1500 of 9916. Loss: 0.3553. Time: 0:00:00.\
| Epoch 3:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9609                         | 1944/9916 [00:01<00:04, 1744.78it/s] Step 2000 of 9916. Loss: 0.3519. Time: 0:00:01.\
| Epoch 3:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                       | 2496/9916 [00:01<00:04, 1777.30it/s] Step 2500 of 9916. Loss: 0.3488. Time: 0:00:01.\
| Epoch 3:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                      | 2856/9916 [00:01<00:03, 1784.99it/s] Step 3000 of 9916. Loss: 0.3522. Time: 0:00:01.\
| Epoch 3:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                    | 3396/9916 [00:01<00:03, 1755.95it/s] Step 3500 of 9916. Loss: 0.3520. Time: 0:00:02.\
| Epoch 3:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                   | 3926/9916 [00:02<00:03, 1754.65it/s] Step 4000 of 9916. Loss: 0.3499. Time: 0:00:02.\
| Epoch 3:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                 | 4470/9916 [00:02<00:03, 1768.80it/s] Step 4500 of 9916. Loss: 0.3486. Time: 0:00:02.\
| Epoch 3:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                | 4980/9916 [00:02<00:03, 1572.05it/s] Step 5000 of 9916. Loss: 0.3503. Time: 0:00:02.\
| Epoch 3:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615              | 5347/9916 [00:03<00:02, 1695.31it/s] Step 5500 of 9916. Loss: 0.3486. Time: 0:00:03.\
| Epoch 3:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610             | 5882/9916 [00:03<00:02, 1749.72it/s] Step 6000 of 9916. Loss: 0.3483. Time: 0:00:03.\
| Epoch 3:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613           | 6418/9916 [00:03<00:02, 1648.75it/s] Step 6500 of 9916. Loss: 0.3463. Time: 0:00:03.\
| Epoch 3:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608          | 6944/9916 [00:04<00:01, 1710.24it/s] Step 7000 of 9916. Loss: 0.3449. Time: 0:00:04.\
| Epoch 3:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7465/9916 [00:04<00:01, 1719.47it/s] Step 7500 of 9916. Loss: 0.3434. Time: 0:00:04.\
| Epoch 3:  81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615      | 7992/9916 [00:04<00:01, 1399.61it/s] Step 8000 of 9916. Loss: 0.3426. Time: 0:00:04.\
| Epoch 3:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8350/9916 [00:04<00:00, 1569.18it/s] Step 8500 of 9916. Loss: 0.3432. Time: 0:00:05.\
| Epoch 3:  89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611    | 8841/9916 [00:05<00:00, 1483.05it/s] Step 9000 of 9916. Loss: 0.3425. Time: 0:00:05.\
| Epoch 3:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9344/9916 [00:05<00:00, 1604.53it/s] Step 9500 of 9916. Loss: 0.3407. Time: 0:00:05.\
| Epoch 3: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1681.64it/s]\
Train accuracy for this epoch: 0.8574\
| Epoch validation 3: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12150.27it/s]\
Val accuracy: 0.8614\
End of epoch 3/30, Train Loss: 0.3406, Val Loss: 0.3348, Train F1 Score: 0.8596799969673157, Val F1 Score: 0.8639, Learning rate scheduler: 0.00039999999999999996.\
Epoch time: 0:00:06, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 4:   4%|\uc0\u9608 \u9615                              | 380/9916 [00:00<00:05, 1869.15it/s] Step 500 of 9916. Loss: 0.3223. Time: 0:00:00.\
| Epoch 4:  10%|\uc0\u9608 \u9608 \u9609                             | 943/9916 [00:00<00:04, 1825.72it/s] Step 1000 of 9916. Loss: 0.3071. Time: 0:00:00.\
| Epoch 4:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9612                          | 1500/9916 [00:00<00:04, 1842.67it/s] Step 1500 of 9916. Loss: 0.3078. Time: 0:00:00.\
| Epoch 4:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9611                         | 1869/9916 [00:01<00:04, 1836.48it/s] Step 2000 of 9916. Loss: 0.3065. Time: 0:00:01.\
| Epoch 4:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                       | 2430/9916 [00:01<00:04, 1808.92it/s] Step 2500 of 9916. Loss: 0.3079. Time: 0:00:01.\
| Epoch 4:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                      | 2995/9916 [00:01<00:03, 1806.58it/s] Step 3000 of 9916. Loss: 0.3024. Time: 0:00:01.\
| Epoch 4:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                    | 3378/9916 [00:01<00:03, 1857.84it/s] Step 3500 of 9916. Loss: 0.3025. Time: 0:00:01.\
| Epoch 4:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                   | 3937/9916 [00:02<00:03, 1847.41it/s] Step 4000 of 9916. Loss: 0.3024. Time: 0:00:02.\
| Epoch 4:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                 | 4496/9916 [00:02<00:02, 1836.41it/s] Step 4500 of 9916. Loss: 0.3039. Time: 0:00:02.\
| Epoch 4:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                | 4867/9916 [00:02<00:02, 1792.64it/s] Step 5000 of 9916. Loss: 0.3051. Time: 0:00:02.\
| Epoch 4:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613              | 5431/9916 [00:02<00:02, 1823.54it/s] Step 5500 of 9916. Loss: 0.3051. Time: 0:00:03.\
| Epoch 4:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5984/9916 [00:03<00:02, 1813.31it/s] Step 6000 of 9916. Loss: 0.3042. Time: 0:00:03.\
| Epoch 4:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615           | 6348/9916 [00:03<00:01, 1810.26it/s] Step 6500 of 9916. Loss: 0.3037. Time: 0:00:03.\
| Epoch 4:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6904/9916 [00:03<00:01, 1752.51it/s] Step 7000 of 9916. Loss: 0.3022. Time: 0:00:03.\
| Epoch 4:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7457/9916 [00:04<00:01, 1808.93it/s] Step 7500 of 9916. Loss: 0.3026. Time: 0:00:04.\
| Epoch 4:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611       | 7841/9916 [00:04<00:01, 1822.48it/s] Step 8000 of 9916. Loss: 0.3016. Time: 0:00:04.\
| Epoch 4:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613     | 8412/9916 [00:04<00:00, 1871.91it/s] Step 8500 of 9916. Loss: 0.3003. Time: 0:00:04.\
| Epoch 4:  91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8985/9916 [00:04<00:00, 1839.00it/s] Step 9000 of 9916. Loss: 0.3005. Time: 0:00:04.\
| Epoch 4:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9355/9916 [00:05<00:00, 1809.29it/s] Step 9500 of 9916. Loss: 0.3009. Time: 0:00:05.\
| Epoch 4: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1819.38it/s]\
Train accuracy for this epoch: 0.8740\
| Epoch validation 4: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12222.28it/s]\
Val accuracy: 0.8721\
End of epoch 4/30, Train Loss: 0.3016, Val Loss: 0.3138, Train F1 Score: 0.8755788207054138, Val F1 Score: 0.8726, Learning rate scheduler: 0.0004222222222222222.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 5:   4%|\uc0\u9608                               | 357/9916 [00:00<00:05, 1783.55it/s] Step 500 of 9916. Loss: 0.2758. Time: 0:00:00.\
| Epoch 5:   9%|\uc0\u9608 \u9608 \u9610                             | 902/9916 [00:00<00:05, 1795.55it/s] Step 1000 of 9916. Loss: 0.2825. Time: 0:00:00.\
| Epoch 5:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                          | 1440/9916 [00:00<00:04, 1758.81it/s] Step 1500 of 9916. Loss: 0.2826. Time: 0:00:00.\
| Epoch 5:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608                         | 1996/9916 [00:01<00:04, 1780.82it/s] Step 2000 of 9916. Loss: 0.2831. Time: 0:00:01.\
| Epoch 5:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                       | 2372/9916 [00:01<00:04, 1828.54it/s] Step 2500 of 9916. Loss: 0.2819. Time: 0:00:01.\
| Epoch 5:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                      | 2928/9916 [00:01<00:03, 1831.61it/s] Step 3000 of 9916. Loss: 0.2833. Time: 0:00:01.\
| Epoch 5:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                    | 3474/9916 [00:01<00:03, 1739.45it/s] Step 3500 of 9916. Loss: 0.2799. Time: 0:00:01.\
| Epoch 5:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                   | 3832/9916 [00:02<00:03, 1759.90it/s] Step 4000 of 9916. Loss: 0.2804. Time: 0:00:02.\
| Epoch 5:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                 | 4363/9916 [00:02<00:03, 1754.51it/s] Step 4500 of 9916. Loss: 0.2809. Time: 0:00:02.\
| Epoch 5:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                | 4900/9916 [00:02<00:02, 1777.16it/s] Step 5000 of 9916. Loss: 0.2794. Time: 0:00:02.\
| Epoch 5:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613              | 5451/9916 [00:03<00:02, 1813.30it/s] Step 5500 of 9916. Loss: 0.2788. Time: 0:00:03.\
| Epoch 5:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615            | 5997/9916 [00:03<00:02, 1803.62it/s] Step 6000 of 9916. Loss: 0.2783. Time: 0:00:03.\
| Epoch 5:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615           | 6357/9916 [00:03<00:02, 1733.90it/s] Step 6500 of 9916. Loss: 0.2780. Time: 0:00:03.\
| Epoch 5:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6903/9916 [00:03<00:01, 1761.45it/s] Step 7000 of 9916. Loss: 0.2765. Time: 0:00:03.\
| Epoch 5:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7459/9916 [00:04<00:01, 1783.56it/s] Step 7500 of 9916. Loss: 0.2758. Time: 0:00:04.\
| Epoch 5:  81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615      | 7995/9916 [00:04<00:01, 1765.97it/s] Step 8000 of 9916. Loss: 0.2762. Time: 0:00:04.\
| Epoch 5:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8348/9916 [00:04<00:00, 1742.72it/s] Step 8500 of 9916. Loss: 0.2754. Time: 0:00:04.\
| Epoch 5:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610    | 8882/9916 [00:05<00:00, 1749.60it/s] Step 9000 of 9916. Loss: 0.2745. Time: 0:00:05.\
| Epoch 5:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9432/9916 [00:05<00:00, 1784.95it/s] Step 9500 of 9916. Loss: 0.2745. Time: 0:00:05.\
| Epoch 5: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1771.62it/s]\
Train accuracy for this epoch: 0.8868\
| Epoch validation 5: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12189.23it/s]\
Val accuracy: 0.8775\
End of epoch 5/30, Train Loss: 0.2749, Val Loss: 0.3008, Train F1 Score: 0.8880520462989807, Val F1 Score: 0.8808, Learning rate scheduler: 0.0004444444444444444.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 6:   4%|\uc0\u9608 \u9615                              | 386/9916 [00:00<00:05, 1877.31it/s] Step 500 of 9916. Loss: 0.2568. Time: 0:00:00.\
| Epoch 6:  10%|\uc0\u9608 \u9608 \u9608                             | 972/9916 [00:00<00:04, 1899.51it/s] Step 1000 of 9916. Loss: 0.2585. Time: 0:00:00.\
| Epoch 6:  14%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                          | 1365/9916 [00:00<00:04, 1903.13it/s] Step 1500 of 9916. Loss: 0.2631. Time: 0:00:00.\
| Epoch 6:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9610                         | 1941/9916 [00:01<00:04, 1868.24it/s] Step 2000 of 9916. Loss: 0.2635. Time: 0:00:01.\
| Epoch 6:  23%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                        | 2317/9916 [00:01<00:04, 1843.99it/s] Step 2500 of 9916. Loss: 0.2635. Time: 0:00:01.\
| Epoch 6:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                      | 2871/9916 [00:01<00:03, 1826.76it/s] Step 3000 of 9916. Loss: 0.2619. Time: 0:00:01.\
| Epoch 6:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                    | 3441/9916 [00:01<00:03, 1869.37it/s] Step 3500 of 9916. Loss: 0.2583. Time: 0:00:01.\
| Epoch 6:  38%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                   | 3816/9916 [00:02<00:03, 1847.65it/s] Step 4000 of 9916. Loss: 0.2588. Time: 0:00:02.\
| Epoch 6:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                 | 4384/9916 [00:02<00:02, 1872.35it/s] Step 4500 of 9916. Loss: 0.2581. Time: 0:00:02.\
| Epoch 6:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                | 4948/9916 [00:02<00:02, 1841.40it/s] Step 5000 of 9916. Loss: 0.2577. Time: 0:00:02.\
| Epoch 6:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608               | 5319/9916 [00:02<00:02, 1838.07it/s] Step 5500 of 9916. Loss: 0.2568. Time: 0:00:02.\
| Epoch 6:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610             | 5891/9916 [00:03<00:02, 1815.38it/s] Step 6000 of 9916. Loss: 0.2556. Time: 0:00:03.\
| Epoch 6:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6468/9916 [00:03<00:01, 1863.45it/s] Step 6500 of 9916. Loss: 0.2570. Time: 0:00:03.\
| Epoch 6:  69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611          | 6844/9916 [00:03<00:01, 1809.57it/s] Step 7000 of 9916. Loss: 0.2572. Time: 0:00:03.\
| Epoch 6:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614        | 7391/9916 [00:03<00:01, 1799.18it/s] Step 7500 of 9916. Loss: 0.2570. Time: 0:00:04.\
| Epoch 6:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7944/9916 [00:04<00:01, 1817.63it/s] Step 8000 of 9916. Loss: 0.2564. Time: 0:00:04.\
| Epoch 6:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615     | 8325/9916 [00:04<00:00, 1859.85it/s] Step 8500 of 9916. Loss: 0.2569. Time: 0:00:04.\
| Epoch 6:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610    | 8881/9916 [00:04<00:00, 1822.73it/s] Step 9000 of 9916. Loss: 0.2564. Time: 0:00:04.\
| Epoch 6:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9434/9916 [00:05<00:00, 1819.17it/s] Step 9500 of 9916. Loss: 0.2560. Time: 0:00:05.\
| Epoch 6: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1840.88it/s]\
Train accuracy for this epoch: 0.8957\
| Epoch validation 6: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12268.30it/s]\
Val accuracy: 0.8773\
End of epoch 6/30, Train Loss: 0.2564, Val Loss: 0.3005, Train F1 Score: 0.8967203497886658, Val F1 Score: 0.8798, Learning rate scheduler: 0.00046666666666666666.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 7:   4%|\uc0\u9608 \u9615                              | 362/9916 [00:00<00:05, 1811.00it/s] Step 500 of 9916. Loss: 0.2337. Time: 0:00:00.\
| Epoch 7:   9%|\uc0\u9608 \u9608 \u9610                             | 914/9916 [00:00<00:05, 1797.90it/s] Step 1000 of 9916. Loss: 0.2411. Time: 0:00:00.\
| Epoch 7:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9613                          | 1457/9916 [00:00<00:04, 1787.87it/s] Step 1500 of 9916. Loss: 0.2424. Time: 0:00:00.\
| Epoch 7:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9612                         | 1832/9916 [00:01<00:04, 1826.54it/s] Step 2000 of 9916. Loss: 0.2413. Time: 0:00:01.\
| Epoch 7:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                       | 2403/9916 [00:01<00:04, 1870.93it/s] Step 2500 of 9916. Loss: 0.2432. Time: 0:00:01.\
| Epoch 7:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                      | 2960/9916 [00:01<00:03, 1819.01it/s] Step 3000 of 9916. Loss: 0.2416. Time: 0:00:01.\
| Epoch 7:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                    | 3356/9916 [00:01<00:03, 1887.60it/s] Step 3500 of 9916. Loss: 0.2425. Time: 0:00:01.\
| Epoch 7:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                   | 3931/9916 [00:02<00:03, 1831.87it/s] Step 4000 of 9916. Loss: 0.2417. Time: 0:00:02.\
| Epoch 7:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                 | 4486/9916 [00:02<00:02, 1828.47it/s] Step 4500 of 9916. Loss: 0.2431. Time: 0:00:02.\
| Epoch 7:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                | 4867/9916 [00:02<00:02, 1867.85it/s] Step 5000 of 9916. Loss: 0.2443. Time: 0:00:02.\
| Epoch 7:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613              | 5428/9916 [00:02<00:02, 1736.32it/s] Step 5500 of 9916. Loss: 0.2428. Time: 0:00:03.\
| Epoch 7:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5982/9916 [00:03<00:02, 1806.49it/s] Step 6000 of 9916. Loss: 0.2412. Time: 0:00:03.\
| Epoch 7:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615           | 6346/9916 [00:03<00:01, 1797.05it/s] Step 6500 of 9916. Loss: 0.2396. Time: 0:00:03.\
| Epoch 7:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6900/9916 [00:03<00:01, 1817.27it/s] Step 7000 of 9916. Loss: 0.2393. Time: 0:00:03.\
| Epoch 7:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7448/9916 [00:04<00:01, 1763.67it/s] Step 7500 of 9916. Loss: 0.2406. Time: 0:00:04.\
| Epoch 7:  81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615      | 7990/9916 [00:04<00:01, 1790.45it/s] Step 8000 of 9916. Loss: 0.2409. Time: 0:00:04.\
| Epoch 7:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8355/9916 [00:04<00:00, 1736.88it/s] Step 8500 of 9916. Loss: 0.2401. Time: 0:00:04.\
| Epoch 7:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609    | 8901/9916 [00:04<00:00, 1777.19it/s] Step 9000 of 9916. Loss: 0.2396. Time: 0:00:04.\
| Epoch 7:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9448/9916 [00:05<00:00, 1804.90it/s] Step 9500 of 9916. Loss: 0.2393. Time: 0:00:05.\
| Epoch 7: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1810.88it/s]\
Train accuracy for this epoch: 0.9034\
| Epoch validation 7: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12159.22it/s]\
Val accuracy: 0.8840\
End of epoch 7/30, Train Loss: 0.2405, Val Loss: 0.2901, Train F1 Score: 0.9043660759925842, Val F1 Score: 0.8848, Learning rate scheduler: 0.0004888888888888889.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 8:   4%|\uc0\u9608 \u9615                              | 380/9916 [00:00<00:05, 1843.92it/s] Step 500 of 9916. Loss: 0.2160. Time: 0:00:00.\
| Epoch 8:  10%|\uc0\u9608 \u9608 \u9609                             | 951/9916 [00:00<00:04, 1840.08it/s] Step 1000 of 9916. Loss: 0.2157. Time: 0:00:00.\
| Epoch 8:  13%|\uc0\u9608 \u9608 \u9608 \u9609                           | 1321/9916 [00:00<00:04, 1816.51it/s] Step 1500 of 9916. Loss: 0.2149. Time: 0:00:00.\
| Epoch 8:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9611                         | 1875/9916 [00:01<00:04, 1799.19it/s] Step 2000 of 9916. Loss: 0.2190. Time: 0:00:01.\
| Epoch 8:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                       | 2432/9916 [00:01<00:04, 1781.35it/s] Step 2500 of 9916. Loss: 0.2179. Time: 0:00:01.\
| Epoch 8:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                      | 2980/9916 [00:01<00:04, 1445.20it/s] Step 3000 of 9916. Loss: 0.2211. Time: 0:00:01.\
| Epoch 8:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                     | 3329/9916 [00:01<00:04, 1581.34it/s] Step 3500 of 9916. Loss: 0.2200. Time: 0:00:02.\
| Epoch 8:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                   | 3882/9916 [00:02<00:03, 1740.07it/s] Step 4000 of 9916. Loss: 0.2209. Time: 0:00:02.\
| Epoch 8:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                 | 4426/9916 [00:02<00:03, 1735.33it/s] Step 4500 of 9916. Loss: 0.2243. Time: 0:00:02.\
| Epoch 8:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                | 4962/9916 [00:02<00:02, 1717.27it/s] Step 5000 of 9916. Loss: 0.2254. Time: 0:00:02.\
| Epoch 8:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612              | 5493/9916 [00:03<00:02, 1743.14it/s] Step 5500 of 9916. Loss: 0.2281. Time: 0:00:03.\
| Epoch 8:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611             | 5843/9916 [00:03<00:02, 1729.35it/s] Step 6000 of 9916. Loss: 0.2271. Time: 0:00:03.\
| Epoch 8:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614           | 6402/9916 [00:03<00:01, 1789.11it/s] Step 6500 of 9916. Loss: 0.2268. Time: 0:00:03.\
| Epoch 8:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6936/9916 [00:03<00:01, 1707.58it/s] Step 7000 of 9916. Loss: 0.2264. Time: 0:00:04.\
| Epoch 8:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7465/9916 [00:04<00:01, 1656.57it/s] Step 7500 of 9916. Loss: 0.2263. Time: 0:00:04.\
| Epoch 8:  81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615      | 7996/9916 [00:04<00:01, 1661.00it/s] Step 8000 of 9916. Loss: 0.2284. Time: 0:00:04.\
| Epoch 8:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8376/9916 [00:04<00:00, 1777.03it/s] Step 8500 of 9916. Loss: 0.2278. Time: 0:00:04.\
| Epoch 8:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609    | 8923/9916 [00:05<00:00, 1807.50it/s] Step 9000 of 9916. Loss: 0.2279. Time: 0:00:05.\
| Epoch 8:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611  | 9463/9916 [00:05<00:00, 1704.63it/s] Step 9500 of 9916. Loss: 0.2281. Time: 0:00:05.\
| Epoch 8: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1729.46it/s]\
Train accuracy for this epoch: 0.9091\
| Epoch validation 8: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12225.67it/s]\
Val accuracy: 0.8838\
End of epoch 8/30, Train Loss: 0.2280, Val Loss: 0.2866, Train F1 Score: 0.9097957015037537, Val F1 Score: 0.8847, Learning rate scheduler: 0.0005111111111111111.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 9:   4%|\uc0\u9608 \u9615                              | 372/9916 [00:00<00:05, 1723.73it/s] Step 500 of 9916. Loss: 0.2184. Time: 0:00:00.\
| Epoch 9:   9%|\uc0\u9608 \u9608 \u9610                             | 904/9916 [00:00<00:05, 1748.47it/s] Step 1000 of 9916. Loss: 0.2105. Time: 0:00:00.\
| Epoch 9:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9613                          | 1467/9916 [00:00<00:04, 1815.61it/s] Step 1500 of 9916. Loss: 0.2105. Time: 0:00:00.\
| Epoch 9:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9612                         | 1828/9916 [00:01<00:04, 1705.20it/s] Step 2000 of 9916. Loss: 0.2143. Time: 0:00:01.\
| Epoch 9:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                       | 2389/9916 [00:01<00:04, 1803.21it/s] Step 2500 of 9916. Loss: 0.2153. Time: 0:00:01.\
| Epoch 9:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                      | 2948/9916 [00:01<00:03, 1814.23it/s] Step 3000 of 9916. Loss: 0.2162. Time: 0:00:01.\
| Epoch 9:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                    | 3494/9916 [00:01<00:03, 1763.90it/s] Step 3500 of 9916. Loss: 0.2187. Time: 0:00:01.\
| Epoch 9:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                   | 3874/9916 [00:02<00:03, 1792.29it/s] Step 4000 of 9916. Loss: 0.2162. Time: 0:00:02.\
| Epoch 9:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                 | 4413/9916 [00:02<00:03, 1780.36it/s] Step 4500 of 9916. Loss: 0.2176. Time: 0:00:02.\
| Epoch 9:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                | 4942/9916 [00:02<00:02, 1726.90it/s] Step 5000 of 9916. Loss: 0.2186. Time: 0:00:02.\
| Epoch 9:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608               | 5318/9916 [00:02<00:02, 1799.44it/s] Step 5500 of 9916. Loss: 0.2174. Time: 0:00:03.\
| Epoch 9:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610             | 5898/9916 [00:03<00:02, 1881.30it/s] Step 6000 of 9916. Loss: 0.2161. Time: 0:00:03.\
| Epoch 9:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6464/9916 [00:03<00:02, 1635.49it/s] Step 6500 of 9916. Loss: 0.2161. Time: 0:00:03.\
| Epoch 9:  71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615         | 6995/9916 [00:03<00:01, 1706.37it/s] Step 7000 of 9916. Loss: 0.2161. Time: 0:00:03.\
| Epoch 9:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614        | 7362/9916 [00:04<00:01, 1765.37it/s] Step 7500 of 9916. Loss: 0.2150. Time: 0:00:04.\
| Epoch 9:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609       | 7908/9916 [00:04<00:01, 1759.09it/s] Step 8000 of 9916. Loss: 0.2142. Time: 0:00:04.\
| Epoch 9:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8442/9916 [00:04<00:00, 1759.42it/s] Step 8500 of 9916. Loss: 0.2154. Time: 0:00:04.\
| Epoch 9:  91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8995/9916 [00:05<00:00, 1815.65it/s] Step 9000 of 9916. Loss: 0.2157. Time: 0:00:05.\
| Epoch 9:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9369/9916 [00:05<00:00, 1841.99it/s] Step 9500 of 9916. Loss: 0.2159. Time: 0:00:05.\
| Epoch 9: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1783.54it/s]\
Train accuracy for this epoch: 0.9144\
| Epoch validation 9: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12240.42it/s]\
Val accuracy: 0.8795\
End of epoch 9/30, Train Loss: 0.2164, Val Loss: 0.2927, Train F1 Score: 0.9149341583251953, Val F1 Score: 0.8848, Learning rate scheduler: 0.0005333333333333333.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 10:   4%|\uc0\u9608                              | 358/9916 [00:00<00:05, 1753.46it/s] Step 500 of 9916. Loss: 0.2059. Time: 0:00:00.\
| Epoch 10:   9%|\uc0\u9608 \u9608 \u9611                            | 896/9916 [00:00<00:05, 1790.17it/s] Step 1000 of 9916. Loss: 0.2095. Time: 0:00:00.\
| Epoch 10:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1440/9916 [00:00<00:04, 1795.23it/s] Step 1500 of 9916. Loss: 0.2045. Time: 0:00:00.\
| Epoch 10:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9610                        | 1989/9916 [00:01<00:04, 1805.26it/s] Step 2000 of 9916. Loss: 0.2069. Time: 0:00:01.\
| Epoch 10:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                       | 2357/9916 [00:01<00:04, 1797.99it/s] Step 2500 of 9916. Loss: 0.2048. Time: 0:00:01.\
| Epoch 10:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                     | 2913/9916 [00:01<00:03, 1822.48it/s] Step 3000 of 9916. Loss: 0.2016. Time: 0:00:01.\
| Epoch 10:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                    | 3461/9916 [00:01<00:03, 1730.97it/s] Step 3500 of 9916. Loss: 0.1995. Time: 0:00:01.\
| Epoch 10:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                  | 3997/9916 [00:02<00:03, 1766.39it/s] Step 4000 of 9916. Loss: 0.1994. Time: 0:00:02.\
| Epoch 10:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                 | 4363/9916 [00:02<00:03, 1787.68it/s] Step 4500 of 9916. Loss: 0.2018. Time: 0:00:02.\
| Epoch 10:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614               | 4904/9916 [00:02<00:02, 1783.98it/s] Step 5000 of 9916. Loss: 0.2035. Time: 0:00:02.\
| Epoch 10:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609              | 5447/9916 [00:03<00:02, 1704.08it/s] Step 5500 of 9916. Loss: 0.2041. Time: 0:00:03.\
| Epoch 10:  61%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612            | 6000/9916 [00:03<00:02, 1749.01it/s] Step 6000 of 9916. Loss: 0.2043. Time: 0:00:03.\
| Epoch 10:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6367/9916 [00:03<00:01, 1786.53it/s] Step 6500 of 9916. Loss: 0.2057. Time: 0:00:03.\
| Epoch 10:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615         | 6903/9916 [00:03<00:01, 1716.25it/s] Step 7000 of 9916. Loss: 0.2054. Time: 0:00:03.\
| Epoch 10:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611        | 7425/9916 [00:04<00:01, 1702.75it/s] Step 7500 of 9916. Loss: 0.2053. Time: 0:00:04.\
| Epoch 10:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614      | 7975/9916 [00:04<00:01, 1792.95it/s] Step 8000 of 9916. Loss: 0.2042. Time: 0:00:04.\
| Epoch 10:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613     | 8348/9916 [00:04<00:00, 1781.02it/s] Step 8500 of 9916. Loss: 0.2051. Time: 0:00:04.\
| Epoch 10:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608    | 8897/9916 [00:05<00:00, 1781.71it/s] Step 9000 of 9916. Loss: 0.2059. Time: 0:00:05.\
| Epoch 10:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9436/9916 [00:05<00:00, 1720.36it/s] Step 9500 of 9916. Loss: 0.2064. Time: 0:00:05.\
| Epoch 10: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1761.87it/s]\
Train accuracy for this epoch: 0.9188\
| Epoch validation 10: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12232.32it/s]\
Val accuracy: 0.8781\
End of epoch 10/30, Train Loss: 0.2069, Val Loss: 0.2955, Train F1 Score: 0.9194033145904541, Val F1 Score: 0.8790, Learning rate scheduler: 0.0005555555555555556.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 11:   4%|\uc0\u9608                              | 358/9916 [00:00<00:05, 1791.94it/s] Step 500 of 9916. Loss: 0.1918. Time: 0:00:00.\
| Epoch 11:   9%|\uc0\u9608 \u9608 \u9611                            | 906/9916 [00:00<00:05, 1752.79it/s] Step 1000 of 9916. Loss: 0.2026. Time: 0:00:00.\
| Epoch 11:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1482/9916 [00:00<00:04, 1876.41it/s] Step 1500 of 9916. Loss: 0.1998. Time: 0:00:00.\
| Epoch 11:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9613                        | 1858/9916 [00:01<00:04, 1865.57it/s] Step 2000 of 9916. Loss: 0.1959. Time: 0:00:01.\
| Epoch 11:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                       | 2427/9916 [00:01<00:04, 1870.74it/s] Step 2500 of 9916. Loss: 0.1947. Time: 0:00:01.\
| Epoch 11:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                     | 2958/9916 [00:01<00:04, 1476.28it/s] Step 3000 of 9916. Loss: 0.1914. Time: 0:00:01.\
| Epoch 11:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                   | 3471/9916 [00:02<00:04, 1485.47it/s] Step 3500 of 9916. Loss: 0.1930. Time: 0:00:02.\
| Epoch 11:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                  | 3837/9916 [00:02<00:03, 1648.65it/s] Step 4000 of 9916. Loss: 0.1927. Time: 0:00:02.\
| Epoch 11:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                 | 4396/9916 [00:02<00:03, 1757.44it/s] Step 4500 of 9916. Loss: 0.1957. Time: 0:00:02.\
| Epoch 11:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613               | 4949/9916 [00:02<00:02, 1818.37it/s] Step 5000 of 9916. Loss: 0.1948. Time: 0:00:02.\
| Epoch 11:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608              | 5494/9916 [00:03<00:02, 1724.58it/s] Step 5500 of 9916. Loss: 0.1954. Time: 0:00:03.\
| Epoch 11:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615            | 5864/9916 [00:03<00:02, 1766.89it/s] Step 6000 of 9916. Loss: 0.1970. Time: 0:00:03.\
| Epoch 11:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610           | 6422/9916 [00:03<00:01, 1818.25it/s] Step 6500 of 9916. Loss: 0.1965. Time: 0:00:03.\
| Epoch 11:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613         | 6967/9916 [00:04<00:01, 1763.05it/s] Step 7000 of 9916. Loss: 0.1963. Time: 0:00:04.\
| Epoch 11:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613        | 7326/9916 [00:04<00:01, 1736.37it/s] Step 7500 of 9916. Loss: 0.1958. Time: 0:00:04.\
| Epoch 11:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7875/9916 [00:04<00:01, 1785.90it/s] Step 8000 of 9916. Loss: 0.1962. Time: 0:00:04.\
| Epoch 11:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611     | 8427/9916 [00:04<00:00, 1814.96it/s] Step 8500 of 9916. Loss: 0.1976. Time: 0:00:04.\
| Epoch 11:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8972/9916 [00:05<00:00, 1800.84it/s] Step 9000 of 9916. Loss: 0.1983. Time: 0:00:05.\
| Epoch 11:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9340/9916 [00:05<00:00, 1797.74it/s] Step 9500 of 9916. Loss: 0.1992. Time: 0:00:05.\
| Epoch 11: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1753.09it/s]\
Train accuracy for this epoch: 0.9228\
| Epoch validation 11: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12141.33it/s]\
Val accuracy: 0.8850\
End of epoch 11/30, Train Loss: 0.1984, Val Loss: 0.3009, Train F1 Score: 0.9232158064842224, Val F1 Score: 0.8889, Learning rate scheduler: 0.0005777777777777778.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 12:   4%|\uc0\u9608                              | 364/9916 [00:00<00:05, 1817.81it/s] Step 500 of 9916. Loss: 0.1823. Time: 0:00:00.\
| Epoch 12:   9%|\uc0\u9608 \u9608 \u9610                            | 929/9916 [00:00<00:04, 1848.61it/s] Step 1000 of 9916. Loss: 0.1743. Time: 0:00:00.\
| Epoch 12:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1493/9916 [00:00<00:04, 1850.23it/s] Step 1500 of 9916. Loss: 0.1762. Time: 0:00:00.\
| Epoch 12:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9613                        | 1863/9916 [00:01<00:04, 1730.05it/s] Step 2000 of 9916. Loss: 0.1784. Time: 0:00:01.\
| Epoch 12:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                      | 2441/9916 [00:01<00:04, 1846.98it/s] Step 2500 of 9916. Loss: 0.1810. Time: 0:00:01.\
| Epoch 12:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                     | 2997/9916 [00:01<00:03, 1821.72it/s] Step 3000 of 9916. Loss: 0.1850. Time: 0:00:01.\
| Epoch 12:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                    | 3363/9916 [00:01<00:03, 1764.03it/s] Step 3500 of 9916. Loss: 0.1856. Time: 0:00:01.\
| Epoch 12:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                  | 3901/9916 [00:02<00:03, 1768.88it/s] Step 4000 of 9916. Loss: 0.1860. Time: 0:00:02.\
| Epoch 12:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                 | 4434/9916 [00:02<00:03, 1755.28it/s] Step 4500 of 9916. Loss: 0.1878. Time: 0:00:02.\
| Epoch 12:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612               | 4978/9916 [00:02<00:02, 1788.43it/s] Step 5000 of 9916. Loss: 0.1873. Time: 0:00:02.\
| Epoch 12:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611              | 5347/9916 [00:02<00:02, 1797.32it/s] Step 5500 of 9916. Loss: 0.1872. Time: 0:00:03.\
| Epoch 12:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615            | 5887/9916 [00:03<00:02, 1768.20it/s] Step 6000 of 9916. Loss: 0.1876. Time: 0:00:03.\
| Epoch 12:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610           | 6451/9916 [00:03<00:01, 1831.43it/s] Step 6500 of 9916. Loss: 0.1888. Time: 0:00:03.\
| Epoch 12:  71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613         | 6991/9916 [00:03<00:01, 1720.93it/s] Step 7000 of 9916. Loss: 0.1889. Time: 0:00:03.\
| Epoch 12:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613        | 7346/9916 [00:04<00:01, 1742.59it/s] Step 7500 of 9916. Loss: 0.1909. Time: 0:00:04.\
| Epoch 12:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7894/9916 [00:04<00:01, 1788.57it/s] Step 8000 of 9916. Loss: 0.1916. Time: 0:00:04.\
| Epoch 12:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611     | 8435/9916 [00:04<00:00, 1784.65it/s] Step 8500 of 9916. Loss: 0.1916. Time: 0:00:04.\
| Epoch 12:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8968/9916 [00:05<00:00, 1739.32it/s] Step 9000 of 9916. Loss: 0.1920. Time: 0:00:05.\
| Epoch 12:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9324/9916 [00:05<00:00, 1760.22it/s] Step 9500 of 9916. Loss: 0.1919. Time: 0:00:05.\
| Epoch 12: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1778.09it/s]\
Train accuracy for this epoch: 0.9260\
| Epoch validation 12: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12171.90it/s]\
Val accuracy: 0.8854\
End of epoch 12/30, Train Loss: 0.1912, Val Loss: 0.2988, Train F1 Score: 0.926425576210022, Val F1 Score: 0.8891, Learning rate scheduler: 0.0006000000000000001.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 13:   4%|\uc0\u9608 \u9615                             | 372/9916 [00:00<00:05, 1759.80it/s] Step 500 of 9916. Loss: 0.1939. Time: 0:00:00.\
| Epoch 13:   9%|\uc0\u9608 \u9608 \u9610                            | 933/9916 [00:00<00:04, 1802.73it/s] Step 1000 of 9916. Loss: 0.1827. Time: 0:00:00.\
| Epoch 13:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1488/9916 [00:00<00:04, 1771.30it/s] Step 1500 of 9916. Loss: 0.1833. Time: 0:00:00.\
| Epoch 13:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9613                        | 1853/9916 [00:01<00:04, 1795.57it/s] Step 2000 of 9916. Loss: 0.1819. Time: 0:00:01.\
| Epoch 13:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                       | 2419/9916 [00:01<00:04, 1864.09it/s] Step 2500 of 9916. Loss: 0.1808. Time: 0:00:01.\
| Epoch 13:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                     | 2970/9916 [00:01<00:04, 1735.32it/s] Step 3000 of 9916. Loss: 0.1836. Time: 0:00:01.\
| Epoch 13:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                    | 3327/9916 [00:01<00:03, 1722.30it/s] Step 3500 of 9916. Loss: 0.1853. Time: 0:00:01.\
| Epoch 13:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                  | 3867/9916 [00:02<00:03, 1776.06it/s] Step 4000 of 9916. Loss: 0.1856. Time: 0:00:02.\
| Epoch 13:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                 | 4420/9916 [00:02<00:03, 1791.70it/s] Step 4500 of 9916. Loss: 0.1860. Time: 0:00:02.\
| Epoch 13:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612               | 4969/9916 [00:02<00:02, 1760.38it/s] Step 5000 of 9916. Loss: 0.1847. Time: 0:00:02.\
| Epoch 13:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612              | 5334/9916 [00:02<00:02, 1789.91it/s] Step 5500 of 9916. Loss: 0.1843. Time: 0:00:03.\
| Epoch 13:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615            | 5877/9916 [00:03<00:02, 1786.43it/s] Step 6000 of 9916. Loss: 0.1852. Time: 0:00:03.\
| Epoch 13:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610           | 6444/9916 [00:03<00:01, 1798.14it/s] Step 6500 of 9916. Loss: 0.1868. Time: 0:00:03.\
| Epoch 13:  71%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613         | 6993/9916 [00:03<00:01, 1806.83it/s] Step 7000 of 9916. Loss: 0.1862. Time: 0:00:03.\
| Epoch 13:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7359/9916 [00:04<00:01, 1812.61it/s] Step 7500 of 9916. Loss: 0.1859. Time: 0:00:04.\
| Epoch 13:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7907/9916 [00:04<00:01, 1805.64it/s] Step 8000 of 9916. Loss: 0.1867. Time: 0:00:04.\
| Epoch 13:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611     | 8446/9916 [00:04<00:00, 1772.94it/s] Step 8500 of 9916. Loss: 0.1862. Time: 0:00:04.\
| Epoch 13:  91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614   | 8986/9916 [00:05<00:00, 1792.87it/s] Step 9000 of 9916. Loss: 0.1859. Time: 0:00:05.\
| Epoch 13:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9344/9916 [00:05<00:00, 1765.29it/s] Step 9500 of 9916. Loss: 0.1857. Time: 0:00:05.\
| Epoch 13: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1771.76it/s]\
Train accuracy for this epoch: 0.9291\
| Epoch validation 13: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12207.72it/s]\
Val accuracy: 0.8787\
End of epoch 13/30, Train Loss: 0.1853, Val Loss: 0.3134, Train F1 Score: 0.9295061230659485, Val F1 Score: 0.8757, Learning rate scheduler: 0.0006222222222222223.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 14:   3%|\uc0\u9608                              | 333/9916 [00:00<00:05, 1668.51it/s] Step 500 of 9916. Loss: 0.1997. Time: 0:00:00.\
| Epoch 14:   9%|\uc0\u9608 \u9608 \u9611                            | 874/9916 [00:00<00:05, 1792.92it/s] Step 1000 of 9916. Loss: 0.1789. Time: 0:00:00.\
| Epoch 14:  14%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1423/9916 [00:00<00:04, 1780.20it/s] Step 1500 of 9916. Loss: 0.1738. Time: 0:00:00.\
| Epoch 14:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9611                        | 1961/9916 [00:01<00:04, 1767.05it/s] Step 2000 of 9916. Loss: 0.1733. Time: 0:00:01.\
| Epoch 14:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                      | 2496/9916 [00:01<00:04, 1773.49it/s] Step 2500 of 9916. Loss: 0.1752. Time: 0:00:01.\
| Epoch 14:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                     | 2874/9916 [00:01<00:03, 1837.39it/s] Step 3000 of 9916. Loss: 0.1767. Time: 0:00:01.\
| Epoch 14:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                    | 3434/9916 [00:01<00:03, 1855.80it/s] Step 3500 of 9916. Loss: 0.1756. Time: 0:00:01.\
| Epoch 14:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                  | 3986/9916 [00:02<00:03, 1789.79it/s] Step 4000 of 9916. Loss: 0.1764. Time: 0:00:02.\
| Epoch 14:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                 | 4349/9916 [00:02<00:03, 1641.32it/s] Step 4500 of 9916. Loss: 0.1765. Time: 0:00:02.\
| Epoch 14:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614               | 4908/9916 [00:02<00:02, 1787.52it/s] Step 5000 of 9916. Loss: 0.1783. Time: 0:00:02.\
| Epoch 14:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609              | 5452/9916 [00:03<00:02, 1796.54it/s] Step 5500 of 9916. Loss: 0.1785. Time: 0:00:03.\
| Epoch 14:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5825/9916 [00:03<00:02, 1826.54it/s] Step 6000 of 9916. Loss: 0.1779. Time: 0:00:03.\
| Epoch 14:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611           | 6371/9916 [00:03<00:01, 1779.22it/s] Step 6500 of 9916. Loss: 0.1766. Time: 0:00:03.\
| Epoch 14:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614         | 6941/9916 [00:03<00:01, 1862.73it/s] Step 7000 of 9916. Loss: 0.1770. Time: 0:00:03.\
| Epoch 14:  76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609        | 7500/9916 [00:04<00:01, 1842.38it/s] Step 7500 of 9916. Loss: 0.1778. Time: 0:00:04.\
| Epoch 14:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7869/9916 [00:04<00:01, 1828.25it/s] Step 8000 of 9916. Loss: 0.1783. Time: 0:00:04.\
| Epoch 14:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611     | 8430/9916 [00:04<00:00, 1819.34it/s] Step 8500 of 9916. Loss: 0.1792. Time: 0:00:04.\
| Epoch 14:  91%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614   | 8977/9916 [00:04<00:00, 1809.90it/s] Step 9000 of 9916. Loss: 0.1781. Time: 0:00:05.\
| Epoch 14:  94%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614  | 9340/9916 [00:05<00:00, 1764.20it/s] Step 9500 of 9916. Loss: 0.1788. Time: 0:00:05.\
| Epoch 14: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1792.78it/s]\
Train accuracy for this epoch: 0.9312\
| Epoch validation 14: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12160.65it/s]\
Val accuracy: 0.8828\
End of epoch 14/30, Train Loss: 0.1787, Val Loss: 0.3088, Train F1 Score: 0.9314827919006348, Val F1 Score: 0.8870, Learning rate scheduler: 0.0006444444444444446.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 15:   4%|\uc0\u9608 \u9615                             | 381/9916 [00:00<00:05, 1784.94it/s] Step 500 of 9916. Loss: 0.1595. Time: 0:00:00.\
| Epoch 15:   9%|\uc0\u9608 \u9608 \u9610                            | 926/9916 [00:00<00:05, 1767.19it/s] Step 1000 of 9916. Loss: 0.1567. Time: 0:00:00.\
| Epoch 15:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1494/9916 [00:00<00:04, 1855.01it/s] Step 1500 of 9916. Loss: 0.1623. Time: 0:00:00.\
| Epoch 15:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9613                        | 1870/9916 [00:01<00:04, 1855.79it/s] Step 2000 of 9916. Loss: 0.1668. Time: 0:00:01.\
| Epoch 15:  25%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                      | 2443/9916 [00:01<00:03, 1896.64it/s] Step 2500 of 9916. Loss: 0.1720. Time: 0:00:01.\
| Epoch 15:  28%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                     | 2823/9916 [00:01<00:03, 1836.97it/s] Step 3000 of 9916. Loss: 0.1701. Time: 0:00:01.\
| Epoch 15:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                    | 3375/9916 [00:01<00:03, 1803.25it/s] Step 3500 of 9916. Loss: 0.1707. Time: 0:00:01.\
| Epoch 15:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                  | 3923/9916 [00:02<00:03, 1804.50it/s] Step 4000 of 9916. Loss: 0.1713. Time: 0:00:02.\
| Epoch 15:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                 | 4477/9916 [00:02<00:02, 1826.56it/s] Step 4500 of 9916. Loss: 0.1698. Time: 0:00:02.\
| Epoch 15:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615               | 4848/9916 [00:02<00:02, 1832.81it/s] Step 5000 of 9916. Loss: 0.1719. Time: 0:00:02.\
| Epoch 15:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610              | 5419/9916 [00:02<00:02, 1810.56it/s] Step 5500 of 9916. Loss: 0.1710. Time: 0:00:03.\
| Epoch 15:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613            | 5975/9916 [00:03<00:02, 1832.84it/s] Step 6000 of 9916. Loss: 0.1709. Time: 0:00:03.\
| Epoch 15:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6342/9916 [00:03<00:01, 1801.46it/s] Step 6500 of 9916. Loss: 0.1701. Time: 0:00:03.\
| Epoch 15:  69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615         | 6889/9916 [00:03<00:01, 1803.28it/s] Step 7000 of 9916. Loss: 0.1701. Time: 0:00:03.\
| Epoch 15:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610        | 7439/9916 [00:04<00:01, 1821.79it/s] Step 7500 of 9916. Loss: 0.1712. Time: 0:00:04.\
| Epoch 15:  81%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613      | 7999/9916 [00:04<00:01, 1841.32it/s] Step 8000 of 9916. Loss: 0.1711. Time: 0:00:04.\
| Epoch 15:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613     | 8367/9916 [00:04<00:00, 1822.28it/s] Step 8500 of 9916. Loss: 0.1721. Time: 0:00:04.\
| Epoch 15:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608    | 8922/9916 [00:04<00:00, 1777.09it/s] Step 9000 of 9916. Loss: 0.1724. Time: 0:00:04.\
| Epoch 15:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611  | 9459/9916 [00:05<00:00, 1767.00it/s] Step 9500 of 9916. Loss: 0.1738. Time: 0:00:05.\
| Epoch 15: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1809.25it/s]\
Train accuracy for this epoch: 0.9351\
| Epoch validation 15: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12153.51it/s]\
Val accuracy: 0.8805\
End of epoch 15/30, Train Loss: 0.1733, Val Loss: 0.3150, Train F1 Score: 0.9354538321495056, Val F1 Score: 0.8836, Learning rate scheduler: 0.0006666666666666669.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 16:   4%|\uc0\u9608 \u9615                             | 376/9916 [00:00<00:05, 1780.70it/s] Step 500 of 9916. Loss: 0.1536. Time: 0:00:00.\
| Epoch 16:   9%|\uc0\u9608 \u9608 \u9610                            | 924/9916 [00:00<00:04, 1804.29it/s] Step 1000 of 9916. Loss: 0.1508. Time: 0:00:00.\
| Epoch 16:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1465/9916 [00:00<00:04, 1734.85it/s] Step 1500 of 9916. Loss: 0.1555. Time: 0:00:00.\
| Epoch 16:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9614                        | 1825/9916 [00:01<00:04, 1763.86it/s] Step 2000 of 9916. Loss: 0.1582. Time: 0:00:01.\
| Epoch 16:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                       | 2383/9916 [00:01<00:04, 1795.03it/s] Step 2500 of 9916. Loss: 0.1661. Time: 0:00:01.\
| Epoch 16:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                     | 2936/9916 [00:01<00:03, 1822.18it/s] Step 3000 of 9916. Loss: 0.1655. Time: 0:00:01.\
| Epoch 16:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                   | 3481/9916 [00:01<00:03, 1782.20it/s] Step 3500 of 9916. Loss: 0.1638. Time: 0:00:01.\
| Epoch 16:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614                  | 3854/9916 [00:02<00:03, 1821.61it/s] Step 4000 of 9916. Loss: 0.1633. Time: 0:00:02.\
| Epoch 16:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                 | 4409/9916 [00:02<00:03, 1792.85it/s] Step 4500 of 9916. Loss: 0.1644. Time: 0:00:02.\
| Epoch 16:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613               | 4954/9916 [00:02<00:02, 1789.45it/s] Step 5000 of 9916. Loss: 0.1643. Time: 0:00:02.\
| Epoch 16:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608              | 5497/9916 [00:03<00:02, 1798.57it/s] Step 5500 of 9916. Loss: 0.1671. Time: 0:00:03.\
| Epoch 16:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615            | 5870/9916 [00:03<00:02, 1825.09it/s] Step 6000 of 9916. Loss: 0.1673. Time: 0:00:03.\
| Epoch 16:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610           | 6427/9916 [00:03<00:01, 1837.23it/s] Step 6500 of 9916. Loss: 0.1663. Time: 0:00:03.\
| Epoch 16:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613         | 6975/9916 [00:03<00:01, 1797.39it/s] Step 7000 of 9916. Loss: 0.1663. Time: 0:00:03.\
| Epoch 16:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613        | 7335/9916 [00:04<00:01, 1782.40it/s] Step 7500 of 9916. Loss: 0.1673. Time: 0:00:04.\
| Epoch 16:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7874/9916 [00:04<00:01, 1768.92it/s] Step 8000 of 9916. Loss: 0.1673. Time: 0:00:04.\
| Epoch 16:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8405/9916 [00:04<00:00, 1732.26it/s] Step 8500 of 9916. Loss: 0.1666. Time: 0:00:04.\
| Epoch 16:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8948/9916 [00:05<00:00, 1670.87it/s] Step 9000 of 9916. Loss: 0.1675. Time: 0:00:05.\
| Epoch 16:  96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611  | 9483/9916 [00:05<00:00, 1743.64it/s] Step 9500 of 9916. Loss: 0.1677. Time: 0:00:05.\
| Epoch 16: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1778.76it/s]\
Train accuracy for this epoch: 0.9370\
| Epoch validation 16: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12223.14it/s]\
Val accuracy: 0.8781\
End of epoch 16/30, Train Loss: 0.1679, Val Loss: 0.3161, Train F1 Score: 0.9372787475585938, Val F1 Score: 0.8806, Learning rate scheduler: 0.0006888888888888892.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 17:   4%|\uc0\u9608                              | 363/9916 [00:00<00:05, 1800.16it/s] Step 500 of 9916. Loss: 0.1468. Time: 0:00:00.\
| Epoch 17:   9%|\uc0\u9608 \u9608 \u9611                            | 906/9916 [00:00<00:05, 1792.79it/s] Step 1000 of 9916. Loss: 0.1483. Time: 0:00:00.\
| Epoch 17:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1452/9916 [00:00<00:04, 1772.99it/s] Step 1500 of 9916. Loss: 0.1539. Time: 0:00:00.\
| Epoch 17:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9614                        | 1829/9916 [00:01<00:04, 1827.89it/s] Step 2000 of 9916. Loss: 0.1514. Time: 0:00:01.\
| Epoch 17:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                       | 2390/9916 [00:01<00:04, 1835.58it/s] Step 2500 of 9916. Loss: 0.1565. Time: 0:00:01.\
| Epoch 17:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                     | 2972/9916 [00:01<00:03, 1909.16it/s] Step 3000 of 9916. Loss: 0.1556. Time: 0:00:01.\
| Epoch 17:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                    | 3351/9916 [00:01<00:03, 1791.07it/s] Step 3500 of 9916. Loss: 0.1570. Time: 0:00:01.\
| Epoch 17:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                  | 3911/9916 [00:02<00:03, 1809.13it/s] Step 4000 of 9916. Loss: 0.1595. Time: 0:00:02.\
| Epoch 17:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                 | 4482/9916 [00:02<00:02, 1875.15it/s] Step 4500 of 9916. Loss: 0.1594. Time: 0:00:02.\
| Epoch 17:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615               | 4857/9916 [00:02<00:02, 1853.06it/s] Step 5000 of 9916. Loss: 0.1584. Time: 0:00:02.\
| Epoch 17:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610              | 5414/9916 [00:02<00:02, 1831.14it/s] Step 5500 of 9916. Loss: 0.1580. Time: 0:00:03.\
| Epoch 17:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613            | 5977/9916 [00:03<00:02, 1857.00it/s] Step 6000 of 9916. Loss: 0.1579. Time: 0:00:03.\
| Epoch 17:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6349/9916 [00:03<00:01, 1844.69it/s] Step 6500 of 9916. Loss: 0.1586. Time: 0:00:03.\
| Epoch 17:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615         | 6921/9916 [00:03<00:01, 1879.00it/s] Step 7000 of 9916. Loss: 0.1605. Time: 0:00:03.\
| Epoch 17:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609        | 7481/9916 [00:04<00:01, 1843.49it/s] Step 7500 of 9916. Loss: 0.1609. Time: 0:00:04.\
| Epoch 17:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609       | 7853/9916 [00:04<00:01, 1820.68it/s] Step 8000 of 9916. Loss: 0.1616. Time: 0:00:04.\
| Epoch 17:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8398/9916 [00:04<00:00, 1774.44it/s] Step 8500 of 9916. Loss: 0.1624. Time: 0:00:04.\
| Epoch 17:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8949/9916 [00:04<00:00, 1748.64it/s] Step 9000 of 9916. Loss: 0.1642. Time: 0:00:04.\
| Epoch 17:  96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610  | 9498/9916 [00:05<00:00, 1785.92it/s] Step 9500 of 9916. Loss: 0.1641. Time: 0:00:05.\
| Epoch 17: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1813.64it/s]\
Train accuracy for this epoch: 0.9400\
| Epoch validation 17: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12172.95it/s]\
Val accuracy: 0.8769\
End of epoch 17/30, Train Loss: 0.1647, Val Loss: 0.3341, Train F1 Score: 0.9403022527694702, Val F1 Score: 0.8824, Learning rate scheduler: 0.0007111111111111114.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 18:   3%|\uc0\u9608                              | 345/9916 [00:00<00:05, 1727.76it/s] Step 500 of 9916. Loss: 0.1390. Time: 0:00:00.\
| Epoch 18:   9%|\uc0\u9608 \u9608 \u9611                            | 886/9916 [00:00<00:05, 1792.69it/s] Step 1000 of 9916. Loss: 0.1388. Time: 0:00:00.\
| Epoch 18:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1443/9916 [00:00<00:04, 1803.04it/s] Step 1500 of 9916. Loss: 0.1422. Time: 0:00:00.\
| Epoch 18:  18%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9614                        | 1821/9916 [00:01<00:04, 1843.58it/s] Step 2000 of 9916. Loss: 0.1457. Time: 0:00:01.\
| Epoch 18:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609                       | 2374/9916 [00:01<00:04, 1807.13it/s] Step 2500 of 9916. Loss: 0.1461. Time: 0:00:01.\
| Epoch 18:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                     | 2924/9916 [00:01<00:03, 1779.14it/s] Step 3000 of 9916. Loss: 0.1456. Time: 0:00:01.\
| Epoch 18:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                   | 3474/9916 [00:01<00:03, 1812.98it/s] Step 3500 of 9916. Loss: 0.1467. Time: 0:00:01.\
| Epoch 18:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                  | 3842/9916 [00:02<00:03, 1799.43it/s] Step 4000 of 9916. Loss: 0.1460. Time: 0:00:02.\
| Epoch 18:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                 | 4393/9916 [00:02<00:03, 1783.11it/s] Step 4500 of 9916. Loss: 0.1491. Time: 0:00:02.\
| Epoch 18:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613               | 4928/9916 [00:02<00:03, 1622.27it/s] Step 5000 of 9916. Loss: 0.1507. Time: 0:00:02.\
| Epoch 18:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608              | 5484/9916 [00:03<00:02, 1775.62it/s] Step 5500 of 9916. Loss: 0.1518. Time: 0:00:03.\
| Epoch 18:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5845/9916 [00:03<00:02, 1741.32it/s] Step 6000 of 9916. Loss: 0.1537. Time: 0:00:03.\
| Epoch 18:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611           | 6391/9916 [00:03<00:01, 1784.27it/s] Step 6500 of 9916. Loss: 0.1543. Time: 0:00:03.\
| Epoch 18:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614         | 6933/9916 [00:03<00:01, 1772.12it/s] Step 7000 of 9916. Loss: 0.1559. Time: 0:00:03.\
| Epoch 18:  76%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609        | 7487/9916 [00:04<00:01, 1803.91it/s] Step 7500 of 9916. Loss: 0.1556. Time: 0:00:04.\
| Epoch 18:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608       | 7865/9916 [00:04<00:01, 1705.31it/s] Step 8000 of 9916. Loss: 0.1571. Time: 0:00:04.\
| Epoch 18:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8410/9916 [00:04<00:00, 1696.13it/s] Step 8500 of 9916. Loss: 0.1576. Time: 0:00:04.\
| Epoch 18:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8944/9916 [00:05<00:00, 1756.51it/s] Step 9000 of 9916. Loss: 0.1588. Time: 0:00:05.\
| Epoch 18:  96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611  | 9478/9916 [00:05<00:00, 1689.74it/s] Step 9500 of 9916. Loss: 0.1597. Time: 0:00:05.\
| Epoch 18: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1745.38it/s]\
Train accuracy for this epoch: 0.9418\
| Epoch validation 18: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12216.88it/s]\
Val accuracy: 0.8699\
End of epoch 18/30, Train Loss: 0.1604, Val Loss: 0.3390, Train F1 Score: 0.9420885443687439, Val F1 Score: 0.8668, Learning rate scheduler: 0.0007333333333333336.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 19:   3%|\uc0\u9608                              | 334/9916 [00:00<00:05, 1658.49it/s] Step 500 of 9916. Loss: 0.1399. Time: 0:00:00.\
| Epoch 19:   9%|\uc0\u9608 \u9608 \u9611                            | 892/9916 [00:00<00:06, 1481.76it/s] Step 1000 of 9916. Loss: 0.1465. Time: 0:00:00.\
| Epoch 19:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1445/9916 [00:00<00:04, 1717.22it/s] Step 1500 of 9916. Loss: 0.1430. Time: 0:00:00.\
| Epoch 19:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9614                        | 1835/9916 [00:01<00:04, 1827.16it/s] Step 2000 of 9916. Loss: 0.1491. Time: 0:00:01.\
| Epoch 19:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                       | 2409/9916 [00:01<00:04, 1821.42it/s] Step 2500 of 9916. Loss: 0.1446. Time: 0:00:01.\
| Epoch 19:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612                     | 2946/9916 [00:01<00:04, 1678.35it/s] Step 3000 of 9916. Loss: 0.1466. Time: 0:00:01.\
| Epoch 19:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                   | 3473/9916 [00:02<00:03, 1726.48it/s] Step 3500 of 9916. Loss: 0.1471. Time: 0:00:02.\
| Epoch 19:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615                  | 3841/9916 [00:02<00:03, 1777.37it/s] Step 4000 of 9916. Loss: 0.1497. Time: 0:00:02.\
| Epoch 19:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                 | 4387/9916 [00:02<00:03, 1724.52it/s] Step 4500 of 9916. Loss: 0.1493. Time: 0:00:02.\
| Epoch 19:  50%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613               | 4932/9916 [00:02<00:02, 1745.99it/s] Step 5000 of 9916. Loss: 0.1512. Time: 0:00:02.\
| Epoch 19:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609              | 5465/9916 [00:03<00:02, 1755.93it/s] Step 5500 of 9916. Loss: 0.1522. Time: 0:00:03.\
| Epoch 19:  59%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608             | 5834/9916 [00:03<00:02, 1785.41it/s] Step 6000 of 9916. Loss: 0.1524. Time: 0:00:03.\
| Epoch 19:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611           | 6379/9916 [00:03<00:01, 1802.28it/s] Step 6500 of 9916. Loss: 0.1520. Time: 0:00:03.\
| Epoch 19:  70%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614         | 6937/9916 [00:03<00:01, 1799.69it/s] Step 7000 of 9916. Loss: 0.1536. Time: 0:00:04.\
| Epoch 19:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610        | 7470/9916 [00:04<00:01, 1685.02it/s] Step 7500 of 9916. Loss: 0.1549. Time: 0:00:04.\
| Epoch 19:  79%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609       | 7837/9916 [00:04<00:01, 1759.60it/s] Step 8000 of 9916. Loss: 0.1551. Time: 0:00:04.\
| Epoch 19:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612     | 8378/9916 [00:04<00:00, 1780.57it/s] Step 8500 of 9916. Loss: 0.1555. Time: 0:00:04.\
| Epoch 19:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615   | 8942/9916 [00:05<00:00, 1816.46it/s] Step 9000 of 9916. Loss: 0.1564. Time: 0:00:05.\
| Epoch 19:  96%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610  | 9492/9916 [00:05<00:00, 1793.63it/s] Step 9500 of 9916. Loss: 0.1567. Time: 0:00:05.\
| Epoch 19: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1759.73it/s]\
Train accuracy for this epoch: 0.9426\
| Epoch validation 19: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12200.16it/s]\
Val accuracy: 0.8688\
End of epoch 19/30, Train Loss: 0.1573, Val Loss: 0.3532, Train F1 Score: 0.942798376083374, Val F1 Score: 0.8756, Learning rate scheduler: 0.0007555555555555558.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 20:   4%|\uc0\u9608                              | 371/9916 [00:00<00:05, 1868.17it/s] Step 500 of 9916. Loss: 0.1510. Time: 0:00:00.\
| Epoch 20:   9%|\uc0\u9608 \u9608 \u9610                            | 929/9916 [00:00<00:04, 1842.90it/s] Step 1000 of 9916. Loss: 0.1440. Time: 0:00:00.\
| Epoch 20:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1484/9916 [00:00<00:04, 1828.61it/s] Step 1500 of 9916. Loss: 0.1454. Time: 0:00:00.\
| Epoch 20:  19%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9613                        | 1864/9916 [00:01<00:04, 1861.52it/s] Step 2000 of 9916. Loss: 0.1443. Time: 0:00:01.\
| Epoch 20:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                       | 2421/9916 [00:01<00:04, 1832.05it/s] Step 2500 of 9916. Loss: 0.1480. Time: 0:00:01.\
| Epoch 20:  30%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                     | 2986/9916 [00:01<00:03, 1838.98it/s] Step 3000 of 9916. Loss: 0.1463. Time: 0:00:01.\
| Epoch 20:  34%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                    | 3351/9916 [00:01<00:03, 1792.53it/s] Step 3500 of 9916. Loss: 0.1462. Time: 0:00:01.\
| Epoch 20:  39%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                  | 3910/9916 [00:02<00:03, 1833.60it/s] Step 4000 of 9916. Loss: 0.1480. Time: 0:00:02.\
| Epoch 20:  45%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                 | 4469/9916 [00:02<00:02, 1834.09it/s] Step 4500 of 9916. Loss: 0.1487. Time: 0:00:02.\
| Epoch 20:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615               | 4831/9916 [00:02<00:02, 1771.20it/s] Step 5000 of 9916. Loss: 0.1477. Time: 0:00:02.\
| Epoch 20:  54%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611              | 5372/9916 [00:02<00:02, 1779.51it/s] Step 5500 of 9916. Loss: 0.1480. Time: 0:00:03.\
| Epoch 20:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614            | 5925/9916 [00:03<00:02, 1808.20it/s] Step 6000 of 9916. Loss: 0.1473. Time: 0:00:03.\
| Epoch 20:  65%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609           | 6462/9916 [00:03<00:01, 1729.40it/s] Step 6500 of 9916. Loss: 0.1480. Time: 0:00:03.\
| Epoch 20:  69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609          | 6810/9916 [00:03<00:01, 1724.58it/s] Step 7000 of 9916. Loss: 0.1480. Time: 0:00:03.\
| Epoch 20:  74%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612        | 7373/9916 [00:04<00:01, 1789.08it/s] Step 7500 of 9916. Loss: 0.1497. Time: 0:00:04.\
| Epoch 20:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9615      | 7909/9916 [00:04<00:01, 1764.68it/s] Step 8000 of 9916. Loss: 0.1500. Time: 0:00:04.\
| Epoch 20:  85%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611     | 8451/9916 [00:04<00:00, 1783.29it/s] Step 8500 of 9916. Loss: 0.1511. Time: 0:00:04.\
| Epoch 20:  89%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610    | 8826/9916 [00:04<00:00, 1831.14it/s] Step 9000 of 9916. Loss: 0.1519. Time: 0:00:05.\
| Epoch 20:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613  | 9390/9916 [00:05<00:00, 1838.69it/s] Step 9500 of 9916. Loss: 0.1525. Time: 0:00:05.\
| Epoch 20: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1799.57it/s]\
Train accuracy for this epoch: 0.9451\
| Epoch validation 20: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12247.05it/s]\
Val accuracy: 0.8765\
End of epoch 20/30, Train Loss: 0.1536, Val Loss: 0.3364, Train F1 Score: 0.945319414138794, Val F1 Score: 0.8796, Learning rate scheduler: 0.000777777777777778.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 21:   4%|\uc0\u9608                              | 362/9916 [00:00<00:05, 1767.78it/s] Step 500 of 9916. Loss: 0.1317. Time: 0:00:00.\
| Epoch 21:   9%|\uc0\u9608 \u9608 \u9611                            | 897/9916 [00:00<00:05, 1776.75it/s] Step 1000 of 9916. Loss: 0.1453. Time: 0:00:00.\
| Epoch 21:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9615                         | 1443/9916 [00:00<00:04, 1807.80it/s] Step 1500 of 9916. Loss: 0.1458. Time: 0:00:00.\
| Epoch 21:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9610                        | 1983/9916 [00:01<00:04, 1762.53it/s] Step 2000 of 9916. Loss: 0.1480. Time: 0:00:01.\
| Epoch 21:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                       | 2341/9916 [00:01<00:04, 1770.55it/s] Step 2500 of 9916. Loss: 0.1474. Time: 0:00:01.\
| Epoch 21:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                     | 2882/9916 [00:01<00:03, 1771.94it/s] Step 3000 of 9916. Loss: 0.1454. Time: 0:00:01.\
| Epoch 21:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                    | 3435/9916 [00:01<00:03, 1814.74it/s] Step 3500 of 9916. Loss: 0.1434. Time: 0:00:01.\
| Epoch 21:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                  | 3979/9916 [00:02<00:03, 1763.67it/s] Step 4000 of 9916. Loss: 0.1443. Time: 0:00:02.\
| Epoch 21:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                 | 4349/9916 [00:02<00:03, 1802.64it/s] Step 4500 of 9916. Loss: 0.1463. Time: 0:00:02.\
| Epoch 21:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614               | 4896/9916 [00:02<00:02, 1808.87it/s] Step 5000 of 9916. Loss: 0.1478. Time: 0:00:02.\
| Epoch 21:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609              | 5434/9916 [00:03<00:02, 1755.76it/s] Step 5500 of 9916. Loss: 0.1498. Time: 0:00:03.\
| Epoch 21:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613            | 5969/9916 [00:03<00:02, 1718.38it/s] Step 6000 of 9916. Loss: 0.1499. Time: 0:00:03.\
| Epoch 21:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6333/9916 [00:03<00:02, 1772.89it/s] Step 6500 of 9916. Loss: 0.1495. Time: 0:00:03.\
| Epoch 21:  69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608          | 6867/9916 [00:03<00:01, 1766.59it/s] Step 7000 of 9916. Loss: 0.1489. Time: 0:00:03.\
| Epoch 21:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611        | 7414/9916 [00:04<00:01, 1781.43it/s] Step 7500 of 9916. Loss: 0.1494. Time: 0:00:04.\
| Epoch 21:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614      | 7970/9916 [00:04<00:01, 1822.90it/s] Step 8000 of 9916. Loss: 0.1507. Time: 0:00:04.\
| Epoch 21:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614     | 8334/9916 [00:04<00:00, 1790.92it/s] Step 8500 of 9916. Loss: 0.1511. Time: 0:00:04.\
| Epoch 21:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609    | 8875/9916 [00:05<00:00, 1746.19it/s] Step 9000 of 9916. Loss: 0.1506. Time: 0:00:05.\
| Epoch 21:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9434/9916 [00:05<00:00, 1804.51it/s] Step 9500 of 9916. Loss: 0.1507. Time: 0:00:05.\
| Epoch 21: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1775.92it/s]\
Train accuracy for this epoch: 0.9460\
| Epoch validation 21: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 12196.32it/s]\
Val accuracy: 0.8749\
End of epoch 21/30, Train Loss: 0.1503, Val Loss: 0.3538, Train F1 Score: 0.946186900138855, Val F1 Score: 0.8758, Learning rate scheduler: 0.0008000000000000001.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
| Epoch 22:   4%|\uc0\u9608 \u9615                             | 378/9916 [00:00<00:05, 1784.51it/s] Step 500 of 9916. Loss: 0.1450. Time: 0:00:00.\
| Epoch 22:   9%|\uc0\u9608 \u9608 \u9610                            | 928/9916 [00:00<00:05, 1720.64it/s] Step 1000 of 9916. Loss: 0.1355. Time: 0:00:00.\
| Epoch 22:  15%|\uc0\u9608 \u9608 \u9608 \u9608 \u9614                         | 1454/9916 [00:00<00:04, 1737.70it/s] Step 1500 of 9916. Loss: 0.1343. Time: 0:00:00.\
| Epoch 22:  20%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9610                        | 1992/9916 [00:01<00:04, 1750.81it/s] Step 2000 of 9916. Loss: 0.1380. Time: 0:00:01.\
| Epoch 22:  24%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610                       | 2343/9916 [00:01<00:04, 1714.61it/s] Step 2500 of 9916. Loss: 0.1427. Time: 0:00:01.\
| Epoch 22:  29%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613                     | 2885/9916 [00:01<00:03, 1774.81it/s] Step 3000 of 9916. Loss: 0.1399. Time: 0:00:01.\
| Epoch 22:  35%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608                    | 3435/9916 [00:01<00:03, 1752.68it/s] Step 3500 of 9916. Loss: 0.1365. Time: 0:00:01.\
| Epoch 22:  40%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                  | 3978/9916 [00:02<00:03, 1750.61it/s] Step 4000 of 9916. Loss: 0.1350. Time: 0:00:02.\
| Epoch 22:  44%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611                 | 4336/9916 [00:02<00:03, 1751.83it/s] Step 4500 of 9916. Loss: 0.1359. Time: 0:00:02.\
| Epoch 22:  49%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614               | 4890/9916 [00:02<00:02, 1821.00it/s] Step 5000 of 9916. Loss: 0.1362. Time: 0:00:02.\
| Epoch 22:  55%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9610              | 5428/9916 [00:03<00:02, 1743.55it/s] Step 5500 of 9916. Loss: 0.1397. Time: 0:00:03.\
| Epoch 22:  60%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613            | 5951/9916 [00:03<00:02, 1725.54it/s] Step 6000 of 9916. Loss: 0.1419. Time: 0:00:03.\
| Epoch 22:  64%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612           | 6329/9916 [00:03<00:01, 1803.78it/s] Step 6500 of 9916. Loss: 0.1429. Time: 0:00:03.\
| Epoch 22:  69%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608          | 6867/9916 [00:03<00:01, 1757.11it/s] Step 7000 of 9916. Loss: 0.1446. Time: 0:00:03.\
| Epoch 22:  75%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9611        | 7415/9916 [00:04<00:01, 1780.25it/s] Step 7500 of 9916. Loss: 0.1457. Time: 0:00:04.\
| Epoch 22:  80%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9614      | 7964/9916 [00:04<00:01, 1780.23it/s] Step 8000 of 9916. Loss: 0.1471. Time: 0:00:04.\
| Epoch 22:  84%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9613     | 8339/9916 [00:04<00:00, 1826.00it/s] Step 8500 of 9916. Loss: 0.1482. Time: 0:00:04.\
| Epoch 22:  90%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9609    | 8886/9916 [00:05<00:00, 1784.21it/s] Step 9000 of 9916. Loss: 0.1480. Time: 0:00:05.\
| Epoch 22:  95%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9612  | 9416/9916 [00:05<00:00, 1600.96it/s] Step 9500 of 9916. Loss: 0.1474. Time: 0:00:05.\
| Epoch 22: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 9916/9916 [00:05<00:00, 1739.39it/s]\
Train accuracy for this epoch: 0.9471\
| Epoch validation 22: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 11548.80it/s]\
Val accuracy: 0.8713\
End of epoch 22/30, Train Loss: 0.1473, Val Loss: 0.3685, Train F1 Score: 0.9472864270210266, Val F1 Score: 0.8686, Learning rate scheduler: 0.0008222222222222223.\
Epoch time: 0:00:05, Train time: 0:00:05, Validation time: 0:00:00.\
No validation set improvements observed for 10 epochs. Stopping training early!\
FINISHED TRAINING SUCCESSFULLY!\
Total time took for training: 0:02:05\
Best validation f1 score: tensor(0.8891)\
In Epoch: 12.\
Best validation loss: 0.28656195947837276\
In Epoch: 8.\
Best validation accuracy: tensor(0.8854)\
In Epoch: 12.\
| Evaluation on the test set: 100%|\uc0\u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 \u9608 | 1239/1239 [00:00<00:00, 8865.98it/s]\
Test set F1 Score: 0.8584474921226501, accuracy: 0.8623890280723572, time take to run: 0:00:00.}